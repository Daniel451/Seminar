\documentclass[12pt,twoside]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Meta informations:
\newcommand{\trauthor}{Daniel Speck}
\newcommand{\trtype}{Seminar Paper} %{Seminararbeit} %{Proseminararbeit}
\newcommand{\trcourse}{Brain Modelling}
\newcommand{\trtitle}{Deep Learning: Neural Networks for Object Detection and Tracking Tasks}
\newcommand{\trmatrikelnummer}{632 13 17}
\newcommand{\tremail}{2speck@informatik.uni-hamburg.de}
\newcommand{\trarbeitsbereich}{Knowledge Technology, WTM}
\newcommand{\trdate}{29.05.2015}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Languages:

% Falls die Ausarbeitung in Deutsch erfolgt:
% \usepackage[german]{babel}
% \usepackage[T1]{fontenc}
% \usepackage[latin1]{inputenc}
% \usepackage[latin9]{inputenc}	 				
% \selectlanguage{german}

% If the thesis is written in English:
\usepackage[english]{babel} 						
\selectlanguage{english}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bind packages:
\usepackage{acronym}                    % Acronyms
\usepackage{algorithmic}								% Algorithms and Pseudocode
\usepackage{algorithm}									% Algorithms and Pseudocode
\usepackage{amsfonts}                   % AMS Math Packet (Fonts)
\usepackage{amsmath}                    % AMS Math Packet
\usepackage{amssymb}                    % Additional mathematical symbols
\usepackage{amsthm}
\usepackage{booktabs}                   % Nicer tables
%\usepackage[font=small,labelfont=bf]{caption} % Numbered captions for figures
\usepackage{color}                      % Enables defining of colors via \definecolor
\definecolor{uhhRed}{RGB}{254,0,0}		  % Official Uni Hamburg Red
\definecolor{uhhGrey}{RGB}{122,122,120} % Official Uni Hamburg Grey
\usepackage{fancybox}                   % Gleichungen einrahmen
\usepackage{fancyhdr}										% Packet for nicer headers
%\usepackage{fancyheadings}             % Nicer numbering of headlines

%\usepackage[outer=3.35cm]{geometry} 	  % Type area (size, margins...) !!!Release version
%\usepackage[outer=2.5cm]{geometry} 		% Type area (size, margins...) !!!Print version
%\usepackage{geometry} 									% Type area (size, margins...) !!!Proofread version
\usepackage[outer=3.15cm]{geometry} 	  % Type area (size, margins...) !!!Draft version
\geometry{a4paper,body={5.8in,9in}}

\usepackage{graphicx}                   % Inclusion of graphics
%\usepackage{latexsym}                  % Special symbols
\usepackage{longtable}									% Allow tables over several parges
\usepackage{listings}                   % Nicer source code listings
\usepackage{multicol}										% Content of a table over several columns
\usepackage{multirow}										% Content of a table over several rows
\usepackage{rotating}										% Alows to rotate text and objects
\usepackage[hang]{subfigure}            % Allows to use multiple (partial) figures in a fig
%\usepackage[font=footnotesize,labelfont=rm]{subfig}	% Pictures in a floating environment
\usepackage{tabularx}										% Tables with fixed width but variable rows
\usepackage{url,xspace,boxedminipage}   % Accurate display of URLs
\usepackage{wrapfig} % wrapped figures (with text floating around)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Configurationen:

\hyphenation{whe-ther} 									% Manually use: "\-" in a word: Staats\-ver\-trag

%\lstloadlanguages{C}                   % Set the default language for listings
\DeclareGraphicsExtensions{.pdf,.svg,.jpg,.png,.eps} % first try pdf, then eps, png and jpg
\graphicspath{{./src/}} 								% Path to a folder where all pictures are located
\pagestyle{fancy} 											% Use nicer header and footer

% Redefine the environments for floating objects:
\setcounter{topnumber}{3}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.9} 			  %Standard: 0.7
\renewcommand{\bottomfraction}{0.5}		  %Standard: 0.3
\renewcommand{\textfraction}{0.1}		  	%Standard: 0.2
\renewcommand{\floatpagefraction}{0.8} 	%Standard: 0.5

% Tables with a nicer padding:
\renewcommand{\arraystretch}{1.2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Additional 'theorem' and 'definition' blocks:
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
%\newtheorem{theorem}{Satz}[section]		% Wenn in Deutsch geschrieben wird.
\newtheorem{axiom}{Axiom}[section] 	
%\newtheorem{axiom}{Fakt}[chapter]			% Wenn in Deutsch geschrieben wird.
%Usage:%\begin{axiom}[optional description]%Main part%\end{fakt}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

%Additional types of axioms:
\newtheorem{lemma}[axiom]{Lemma}
\newtheorem{observation}[axiom]{Observation}

%Additional types of definitions:
\theoremstyle{remark}
%\newtheorem{remark}[definition]{Bemerkung} % Wenn in Deutsch geschrieben wird.
\newtheorem{remark}[definition]{Remark} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Provides TODOs within the margin:
\newcommand{\TODO}[1]{\marginpar{\emph{\small{{\bf TODO: } #1}}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abbreviations and mathematical symbols
\newcommand{\modd}{\text{ mod }}
\newcommand{\RS}{\mathbb{R}}
\newcommand{\NS}{\mathbb{N}}
\newcommand{\ZS}{\mathbb{Z}}
\newcommand{\dnormal}{\mathit{N}}
\newcommand{\duniform}{\mathit{U}}

\newcommand{\erdos}{Erd\H{o}s}
\newcommand{\renyi}{-R\'{e}nyi}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document:
\begin{document}
\renewcommand{\headheight}{14.5pt}

\fancyhead{}
\fancyhead[LE]{ \slshape \trauthor}
\fancyhead[LO]{}
\fancyhead[RE]{}
\fancyhead[RO]{ \slshape \trtitle}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Cover Header:
\begin{titlepage}
	\begin{flushleft}
		Universit\"at Hamburg\\
		Department Informatik\\
		\trarbeitsbereich\\
	\end{flushleft}
	\vspace{3.5cm}
	\begin{center}
		\huge \trtitle\\
	\end{center}
	\vspace{3.5cm}
	\begin{center}
		\normalsize\trtype\\
		[0.2cm]
		\Large\trcourse\\
		[1.5cm]
		\Large \trauthor\\
		[0.2cm]
		\normalsize Matr.Nr. \trmatrikelnummer\\
		[0.2cm]
		\normalsize\tremail\\
		[1.5cm]
		\Large \trdate
	\end{center}
	\vfill
\end{titlepage}

	%backsite of cover sheet is empty!
\thispagestyle{empty}
\hspace{1cm}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract:

% Abstract gives a brief summary of the main points of a paper:
\section*{Abstract}
Deep learning and the interrelated deep neural networks are one of the most successful learning strategies at the moment as the computing power for creating such structures rised in the past years via GPU computing. Image and video classifcation, object detection and tracking tasks can be fulfilled with these architectures which perform far better than more classical ones. One focus will be convolutional neural networks and the latest research on (mostly supervised) deep learning architectures.
  

% Lists:
\setcounter{tocdepth}{2} 					% depth of the table of contents (for Seminars 2 is recommented)
\tableofcontents
\pagenumbering{arabic}
\clearpage






%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Content:

% the actual content, usually separated over a number of sections
% each section is assigned a label, in order to be able to put a
% crossreference to it




\section{Introduction}
\label{sec:introduction}

Big data is one of the most present keywords in the last couple of years. With more and more devices being able to capture high-resolution images and videos the data and information available on the internet increases rapidly, rather exponentially but all this data is useless if this flood of information can not be searched, categorized and made easy accessible for humans. As a consequence of this situation classic, mostly static algorithms are "out-of-date" and new, intelligent systems have to be developed. Biological entities are, up to now, by far better when it comes to recognize, classify, sort etc. images or videos compared to computers. This circumstance led to researching intelligent systems that are able to adapt to their input, search for patterns and recognize, track and classify them.
\\
Inspired by biological systems, deep learning and especially convolutional neural networks have become popular because their results in classification and tracking tasks are state-of-the-art.
\\
In this paper, a basic, background information view about artificial neural networks will be given for understanding the underlying concepts which are important to solve complex problems with machine learning architectures.
\\
In addition to that a comprehension of deep neural networks and deep learning will be made to point out the abilities but also the limits of "classic" neural networks. Also some information about the role of GPU-computing in such disciplines will be provided.
\\
For solving complex problems in classification, recognition, tracking etc. domains convolutional neural networks have shown good performances so they will be focused later on. Especially the latest research on these topics and fields of application will be viewed in detail.
\\
An important contest for classification tasks is measuring the performance of such architectures with the ImageNet LSVRC databases and for videos the YouTube 1M database by Google. Both topics will be introduced. One very interesting thing, for example, is the fact that pre-trained networks on videos showing sports did better on non-sports related video categorization than "fresh" networks.




\section{Background information: Artificial neural networks}
\label{sec:ann}

Artificial neural networks are intended to approximate certain functions for machine learning purposes. Fix/static algorithms can be calculated fast by modern computers but fail most times at disciplines requiring "intelligent" behavior. A classic example is recognizing handwritten digits because the shape, color and contrast highly vary in dependence of the used pencil and, of course, of the writing style. As a result classic, static algorithms would fail to identify those varying patterns and therefore fail to appropriately classify handwritten digits.
\\
Such tasks can be fulfilled by artificial neural networks. A common architecture is the multilayer-perceptron as shown in figure \ref{fig:mlp1}.
\\
This artificial neural network, for example, could be used to classify handwritten digits. The images information of input size 5x5, which results in 25 pixels, would be used by the 25 neurons in the input layer. The hidden layers would try to extract the features which are characteristically for each digit and the output layer with 10 neurons models the digits 0 to 9 for representing the calculated digit.
\\
However, such architectures are insufficient for more complex tasks because they need a vast amount of resources, are not optimized and do not make use of any prior-knowledge of the problem. Non-deep structures where every layer is fully-connected turned out to be expensive in terms of computational resources and not optimal considering the results in disciplines of image and video classification, object recognition and tracking.

\begin{figure}[H]
	\centerline{
		\includegraphics[width=0.5\textwidth]{neuralnet1.pdf}
	}
	{\caption{An example of a classic, fully-connected multilayer-perceptron. The input layer holds 20 neurons, hidden layer 1 10 neurons, hidden layer 2 5 neurons and the output layer 2 neurons. All arrows but the short ones represent randomly initialized weights.}\label{fig:mlp1}}
\end{figure}


\section{Deep neural networks}
\label{sec:dnn}

Classic, small neural networks can not succeed on complex tasks such as object detection in high-resolution, real world images. The variety of features, blurry backgrounds, one or several objects in an image and other factors render detection, tracking and classification tasks challenging. The ability to detect, track and distinguish real world objects demands complex structures with a much larger capability of solving complex problems.
\\
As computing power rises and GPU-computing became popular neural networks are no longer limited to a few layers containing just some neurons. Modern solutions (2014) can carry tens of layers with thousands of neurons and millions of connections \cite{GoogleLargeScaleVideoClassification-Karpathy}. Complex structures like this enable computing complex problems which arise with tasks like image classification in real world images.
\\
Deep neural networks with GPU-optimized code can be considerably faster than CPU-optimized code and hence allow larger, more accurate architectures \cite{MultiColumnDeepNeuralNetworksClassification-Ciresan}.




\section{Convolutional neural networks and image processing}
\label{sec:cnn}

For deep learning purposes (classic / fully-connected) multilayer perceptrons consume a sizable amount of resources for proper training when they are designed to solve complex tasks because the amount of neurons and especially weights increases rapidly with the network's size.
\\
For example, a MLP with three layers, an input layer with 100 neurons, a hidden layer with 25 neurons and an output layer with 10 neurons for classifying images with a size of 10x10 pixels into 10 different classes would have $100 * 25 + 25 * 10 = 2,750$ weights/connections. Training this net would already result in a big time and space complexity. Moreover, as features in images capturing real world scenes are distributed in certain patterns (they cover spatially local correlation, such as shapes), there is no need to have every pixels information being processed by one neuron. Actually in most cases results would be even better, if the pixels information is pre-processed, for instance by edge detection filters but a fully connected layer of neurons is not an optimal solution for this task.
\\
Convolutional neural networks (CNNs) are inspired by biology, instead of connecting every pixels information directly with a neuron to process its information it filters the information in the first layers \cite{ImangeNetClassificationCNN-Krizhevsky}. This procedure is similar to the on processes happening when an biological eye receives stimuli.
\\
The receptive field \footnote{\url{http://en.wikipedia.org/wiki/Receptive_field}} has a vast amount of photoreceptor cells \footnote{\url{http://en.wikipedia.org/wiki/Photoreceptor_cell}} gathering information and converging the received information on to distinctly less retinal ganglion cells \footnote{\url{http://en.wikipedia.org/wiki/Retinal_ganglion_cell}}. This process maps several features and reduces the input dimensionality as well as distinguishes the information to separate "channels" which are then transfered to the corresponding neurons to process features such as color, motion, shapes and so on separately \cite{DeepHierarchiesVisualCortex-kruger}.
\begin{figure}
	\centerline{
		\includegraphics[width=0.3\textwidth]{animal-original.png}
		\qquad
		\includegraphics[width=0.3\textwidth]{animal-edge-detection.png}
	}
	{\caption{Left side: original image, right side: edge-detection kernel processed image. Original image by Michael Plotke, 28th of January, 2013. Open creative commons license.
			\protect\url{http://upload.wikimedia.org/wikipedia/commons/5/50/Vd-Orig.png} and \protect\url{http://upload.wikimedia.org/wikipedia/commons/6/6d/Vd-Edge3.png}}\label{fig:animal-edge-detection}}
\end{figure}
The idea of CNNs is based on this biological processes, the information of an input image is convolved by several filters which try to extract interesting features in the first layer and in following layers this information is pooled and subsampled \cite{ImangeNetClassificationCNN-Krizhevsky}.
\\
Convolution itself is the applying of a function repeatedly of the output of another function and in the context of CNNs it is applying different "filters" over an image to extract the already mentioned features. A convolution layer extracts the pixel information out of an image with kernels \footnote{\url{http://en.wikipedia.org/wiki/Kernel_(image_processing)}}.
\\
\\
Example for a convolution layer: In figure \ref{fig:animal-edge-detection} you can see an image of an animal on the left side (original image) and a kernel processed one on the right side. The used kernel matrix for filtering the left image is shown in equation (\ref{equation:kernal-matrix}).
\begin{wrapfigure}{r}{0.5\textwidth}
	\begin{equation}
		\label{equation:kernal-matrix}
		K_M =
		\begin{bmatrix}
		-1 & -1 & -1 \\
		-1 & 8 & -1 \\
		-1 & -1 & -1 \\
		\end{bmatrix}
	\end{equation}
\end{wrapfigure}
So basically each pixels information in the right, processed image is the result of applying the kernel matrix (\ref{equation:kernal-matrix}) on the same pixel (and the neighboring pixels) in the left image. With a wide variety of different kernels several different features can be extracted from an image. Typical CNNs use tens to hundreds of different kernel filters gathering as much features from an image as possible. The resulting pixel processed by a kernel filter is calculated via the formula:
\begin{equation}
I_{out}(x,y) =
\sum_{a=1}^{3} \sum_{b=1}^{3} I_{in} (x+a-c_x, y+b-c_y) * K_M(a,b)
\end{equation}
Where $c_x$ is the coordinate of the x-center and $c_y$ the coordinate of the y-center of the input image.
For some example input image $I_{in}$ with a dimension of 3x3 pixels the center pixel (coordinates $x=2, y=2$) of the kernel processed output image $I_{out}$ using the kernel filter $K_M$ of equation (\ref{equation:kernal-matrix}) would be calculated like this:
\begin{gather*}
	I_{in} =
	\begin{bmatrix}
	46 & 42 & 50 \\
	44 & 65 & 56 \\
	41 & 52 & 58 \\
	\end{bmatrix}
	\\
	\\
	I_{out}(2,2) = 46 * (-1) + 42 * (-1) + 50 * (-1) + 44 * (-1) + 55 * 8 + 56 * (-1)
	\\+ \;41 * (-1) + 52 * (-1) + 58 * (-1) = 131
\end{gather*}
After processing this filter to the whole image edges would be highlighted and the rest nearly black, like in figure \ref{fig:animal-edge-detection} so that shape features are extracted out of the original image.
\\
\\
Another idea of CNNs is subsampling layers following convolutional layers. Subsampling reduces the overall size of information and therefore not only saves resources for the later classification tasks but also strengthens the detected features in an image. Often max-pooling is used as a subsampling strategy in CNNs \cite{DeepNeuralNetworksObjectDetection-Szegedy, ImangeNetClassificationCNN-Krizhevsky} which determines the most distinctive pixel in a given area. A max-pooling algorithm splits the input in grids and selects the maximum value out of each grid, thus non-maximal values are deleted so that only those information continues to exist which best represents the current feature. Before applying max-pooling the input represents the presence of a feature in one or only some pixels. After this kind of dimensionality reduction the assertion is enlarged to whole area, corresponding to several pixels of the original image. 
\\
Additionally this technique provides robustness to the position of a feature in an image, as the position becomes less important.
\\
\\
The last layers of a CNN regularly consist of fully-connected layers. In comparison to feature extraction, strengthening and dimensionality reduction those layers are supposed to take all gathered features / information and make predictions. If the supplied input contains big shapes of ears, legs etc., maybe filtered trunks, grey-ish color maps and so on the fully-connected layers have to collect and mix all those gathered features / information and to recognize it for finally classifying it as an image of elephants.



\section{Research and field of application}
\label{sec:research_and_application}


\subsection{Image classification}

Alex Krizhevsky et al. have shown in "ImageNet Classification with Deep Convolutional Neural Networks" \cite{ImangeNetClassificationCNN-Krizhevsky} the good performance of CNNs in image classification tasks. Their architecture achieved top-1 and top-5 error rates of 37.5\% and 17.0\% on the ImageNet LSVRC-2010 contest which was the best result in 2012.
\\
The CNN consists of about $650,000$ neurons with $60$ million parameters and nine layers total.
\\
The only preproduction made were resizing the images to a resolution of 256x256 because the images in ImageNet vary in resolution. Out of those images 224x224x3 dimensional patches are extracted. 224x224 in horizontal/vertical dimension and 3 different colors (RBG images). The first layer is a convolution layer which filters the input of 224x224x3 to a kernel map of 96 kernels with the size of 11x11x3 each. This slightly reduces the dimensionality of the input image and extracts 96 different features out of the input.
\\
The second layer is a max-pooling layer which filters the information via 256 5x5x48 kernels. Therefore the dimensionality is further reduced and already extracted features strengthened.
\\
Afterwards convolutional and max-pooling layers follow the the fifth layer until three fully-connected layers with 4096 neurons each try to collect and mix the information and then classify the images.
\\
\\
One key problem with deep learning structures and especially CNNs is overfitting. Because of the size of those networks a huge amount of training data is needed. An interesting method used by Krizhevsky is to design first layer (224x224x3 for Krizhevsky's architecture) slightly smaller than input data (256x256x3) and then not just apply kernel filters on those input data but first extract random 224x224x3 patches out of the original data. Additionally they the horizontal reflections of those patches and altered the intensities of the RGB channels.
\\
This technique can boost the training data set by hundreds or even thousands of samples \cite{ImangeNetClassificationCNN-Krizhevsky}.
\\
\\
Another procedure to reduce overfitting and test errors is called "dropout" \cite{ImprovingNeuralNetworksDropout-Hinton-Krizhevsky}. The idea is to set the output of hidden neurons to zero with a certain probability, mostly $0.5$ \cite{ImangeNetClassificationCNN-Krizhevsky}. This prevents neurons of co-adapting each other which means that neurons can no longer distort its output because they "familiarize" with some neurons of their parent layer and ignore others. With "deactiviting" random neurons in each learning step the presence of an other neuron is not guaranteed so neurons are more likely to learn and focus on robust features rather than on single attractive neurons.

\subsection{Video classification}
More details / information about state of the art object/video detection/classification.


\subsection{Object tracking}



\section{Conclusion}
\label{sec:concl}

Conclusion of the paper.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% hier werden - zum Ende des Textes - die bibliographischen Referenzen
% eingebunden
%
% Insbesondere stehen die eigentlichen Informationen in der Datei
% ``bib.bib''
%
\newpage
\bibliographystyle{plain}
\addcontentsline{toc}{section}{Bibliography}% Add to the TOC
\bibliography{bib}


\end{document}


